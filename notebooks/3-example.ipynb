{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815e2109",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17c463",
   "metadata": {},
   "source": [
    "## Standard setup\n",
    "\n",
    "Note: not all imports are required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b862c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.cache import InMemoryCache\n",
    "from dotenv import load_dotenv\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2a670",
   "metadata": {},
   "source": [
    "## Examples of history\n",
    "* way to capture info said by the AI and User\n",
    "* good way to look at train of thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464eae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"Hello how can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c2ee6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Hello how can I help you?', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6aee91",
   "metadata": {},
   "source": [
    "## Memory Buffers\n",
    "### Short term memory \n",
    "* Can be used for recalling information \n",
    "* Can be used for train of thought reasoning.\n",
    "* Can be used for audit logging of user and AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436d2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"Hello how can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1f0f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: Hello how can I help you?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273cd88",
   "metadata": {},
   "source": [
    "### We can also get the history as a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f948ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"Hi how are you doing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc500dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi!', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Hi how are you doing today?', additional_kwargs={}, example=False)]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "974f79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d439b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: what will ai do in the future to the human race\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' In the future, AI can help human beings in many ways. We can help with tasks that are too difficult or cumbersome for humans to do on their own. For example, AI can be used to automate mundane tasks, such as data collection, analysis, and visualization. AI can also help with more complex tasks, such as medical diagnosis and autonomous robotics. Additionally, AI can help us to better understand the world around us and make more informed decisions. Ultimately, our goal is to create an AI system that can provide humans with a better quality of life.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what will ai do in the future to the human race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb7d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
